==3480030== NVPROF is profiling process 3480030, command: ./train_gpt2cu -e gpt2_124M_bf16.bin
==3480030== Profiling application: ./train_gpt2cu -e gpt2_124M_bf16.bin
==3480030== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   67.30%  8.92100s      1512  5.9001ms  1.4169ms  115.18ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   17.12%  2.26972s       532  4.2664ms  1.6644ms  139.17ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.34%  1.37017s       292  4.6924ms  1.5228ms  96.025ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.10%  145.51ms       288  505.26us  501.72us  513.72us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.82%  108.52ms        24  4.5218ms  4.4474ms  4.6235ms  void fused_classifier_kernel5<bool=1, bool=0>(__nv_bfloat16*, float*, __nv_bfloat16*, float, int const *, int, int, int, int, std::integral_constant<bool, bool=1>)
                    0.51%  67.245ms       336  200.13us  199.04us  203.07us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.49%  65.321ms       288  226.81us  213.85us  253.79us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.48%  63.322ms       576  109.93us  104.41us  115.93us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.42%  56.273ms        64  879.27us  2.4320us  4.3714ms  void adamw_kernel3<__nv_bfloat16, __nv_bfloat16>(__nv_bfloat16*, float*, __nv_bfloat16*, float*, float*, unsigned long, long, long, long, float, float, float, float, float, float, float, float, unsigned int)
                    0.36%  47.214ms        48  983.63us  964.24us  1.0069ms  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.20%  26.409ms       288  91.698us  81.567us  108.73us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.16%  21.028ms       129  163.00us     608ns  2.8450ms  [CUDA memcpy HtoD]
                    0.15%  20.336ms       237  85.804us     512ns  11.156ms  [CUDA memset]
                    0.11%  14.549ms       100  145.49us  141.53us  150.24us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.11%  14.115ms        48  294.07us  290.72us  297.05us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.07%  9.8377ms        96  102.48us  86.046us  122.33us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.07%  9.1978ms        48  191.62us  187.16us  196.70us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.07%  9.1262ms         4  2.2816ms  2.1753ms  2.5841ms  void global_norm_squared_kernel<__nv_bfloat16>(float*, __nv_bfloat16 const *, unsigned long, long)
                    0.04%  5.7110ms        48  118.98us  115.13us  123.42us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.03%  3.4662ms        16  216.64us  1.8880us  1.0675ms  void copy_and_cast_kernel<float, __nv_bfloat16>(float*, __nv_bfloat16 const *, unsigned long, long, long)
                    0.03%  3.4292ms        96  35.721us  34.079us  37.536us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.01%  1.5387ms        24  64.113us  61.599us  68.798us  encoder_forward_kernel3(__nv_bfloat16*, int const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int)
                    0.01%  1.1599ms        24  48.328us  45.472us  60.383us  layernorm_forward_kernel6(__nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.00%  347.80us        96  3.6220us  3.4560us  4.0000us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  264.03us         4  66.006us  64.639us  68.190us  void wte_backward_kernel<int=256>(__nv_bfloat16*, int4 const *, int const *, __nv_bfloat16 const *, int const *, unsigned int, int, int, int)
                    0.00%  120.86us         4  30.215us  30.048us  30.399us  wpe_backward_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int const *, int, int, int, unsigned int)
                    0.00%  71.712us        28  2.5610us  1.4080us  3.8710us  [CUDA memcpy DtoH]
                    0.00%  57.632us         4  14.408us  14.176us  14.720us  ncclKernel_SendRecv_RING_SIMPLE_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)
                    0.00%  31.423us         8  3.9270us  3.2320us  4.7680us  void global_sum_single_block_kernel<float>(float*, float const *, unsigned long)
      API calls:   69.97%  9.83982s        53  185.66ms  6.4650us  419.80ms  cudaDeviceSynchronize
                   17.22%  2.42181s        85  28.492ms  2.3300us  807.35ms  cudaMemcpyAsync
                    5.80%  815.02ms         4  203.76ms  9.3790us  814.99ms  cudaLaunchKernelExC
                    2.25%  315.80ms      1801  175.35us  2.4660us  310.65ms  cudaFuncGetAttributes
                    2.20%  309.31ms        20  15.465ms     310ns  309.27ms  cudaSetDevice
                    1.08%  151.66ms         4  37.916ms  35.251us  132.30ms  cudaHostAlloc
                    0.82%  115.31ms        72  1.6015ms  12.072us  10.266ms  cudaMemcpy
                    0.22%  31.354ms      4864  6.4460us  3.2690us  5.4846ms  cudaLaunchKernel
                    0.15%  20.569ms         1  20.569ms  20.569ms  20.569ms  cudaMallocManaged
                    0.11%  15.114ms         1  15.114ms  15.114ms  15.114ms  cudaGetSymbolAddress
                    0.06%  8.2932ms         1  8.2932ms  8.2932ms  8.2932ms  cudaFreeHost
                    0.05%  7.3183ms       338  21.651us     108ns  1.9874ms  cuDeviceGetAttribute
                    0.02%  2.5474ms       108  23.587us  2.7860us  351.23us  cudaMalloc
                    0.01%  1.8847ms         1  1.8847ms  1.8847ms  1.8847ms  cudaGetDeviceProperties
                    0.01%  1.6304ms        10  163.04us  10.601us  1.1773ms  cudaStreamSynchronize
                    0.01%  1.2568ms        36  34.911us     397ns  1.2190ms  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
                    0.01%  1.1930ms        27  44.187us  5.9370us  68.980us  cudaMemset
                    0.01%  1.0601ms      2401     441ns     304ns  5.3800us  cudaFuncSetAttribute
                    0.01%  968.41us      7728     125ns      81ns  9.1650us  cudaGetLastError
                    0.01%  857.12us       210  4.0810us  1.5700us  53.753us  cudaMemsetAsync
                    0.00%  216.75us       795     272ns     116ns  9.4800us  cuGetProcAddress
                    0.00%  139.15us         1  139.15us  139.15us  139.15us  cudaFree
                    0.00%  112.43us       332     338ns     228ns  6.4990us  cudaThreadExchangeStreamCaptureMode
                    0.00%  103.88us        19  5.4670us     591ns  17.311us  cudaEventRecord
                    0.00%  59.014us         3  19.671us  4.6180us  37.322us  cudaStreamCreateWithFlags
                    0.00%  50.578us         4  12.644us  7.7790us  18.894us  cuDeviceGetName
                    0.00%  30.884us         2  15.442us  15.176us  15.708us  cudaStreamCreate
                    0.00%  29.418us        13  2.2620us     245ns  9.3940us  cudaGetDevice
                    0.00%  28.661us         1  28.661us  28.661us  28.661us  cudaMemGetInfo
                    0.00%  25.911us         4  6.4770us  3.8200us  13.359us  cudaEventSynchronize
                    0.00%  23.544us        11  2.1400us     547ns  3.9330us  cudaStreamWaitEvent
                    0.00%  21.853us         1  21.853us  21.853us  21.853us  cudaProfilerStart
                    0.00%  20.762us         1  20.762us  20.762us  20.762us  cudaMallocHost
                    0.00%  15.790us         4  3.9470us  3.7230us  4.2730us  cudaStreamGetCaptureInfo
                    0.00%  15.750us         4  3.9370us  1.9840us  5.9050us  cuInit
                    0.00%  13.911us        23     604ns     290ns  2.5940us  cudaDeviceGetAttribute
                    0.00%  13.503us         1  13.503us  13.503us  13.503us  cudaStreamDestroy
                    0.00%  12.663us         4  3.1650us  2.6220us  3.9410us  cudaEventElapsedTime
                    0.00%  12.489us        28     446ns     224ns     927ns  cuGetProcAddress
                    0.00%  9.7780us         1  9.7780us  9.7780us  9.7780us  cuDeviceGetPCIBusId
                    0.00%  8.8690us         2  4.4340us  1.7800us  7.0890us  cudaEventCreate
                    0.00%  6.4400us         3  2.1460us     651ns  3.3040us  cudaEventCreateWithFlags
                    0.00%  3.1010us         1  3.1010us  3.1010us  3.1010us  cudaDeviceGetPCIBusId
                    0.00%  2.2070us         6     367ns     145ns  1.3850us  cuDeviceGet
                    0.00%  2.1830us         3     727ns     150ns  1.2840us  cudaDriverGetVersion
                    0.00%  1.8700us         5     374ns     171ns     966ns  cuDeviceGetCount
                    0.00%  1.4850us         2     742ns     381ns  1.1040us  cudaGetDriverEntryPoint
                    0.00%  1.4330us         3     477ns     279ns     624ns  cuModuleGetLoadingMode
                    0.00%  1.3190us         3     439ns     326ns     544ns  cuDeviceTotalMem
                    0.00%     780ns         3     260ns     204ns     324ns  cuDeviceGetUuid
                    0.00%     572ns         3     190ns     140ns     289ns  cuDriverGetVersion

==3480030== NVTX result:
==3480030== Warning: Found 1 invalid range marker(s)
==3480030==   Thread "<unnamed>" (id = 1127575552)
==3480030==     Domain "NCCL"
==3480030==       Range "ncclAllReduce"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  815.36ms         4  203.84ms  59.975us  815.16ms  ncclAllReduce
 GPU activities:  100.00%  57.632us         4  14.408us  14.176us  14.720us  ncclKernel_SendRecv_RING_SIMPLE_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)
      API calls:  100.00%  815.02ms         4  203.76ms  9.3790us  814.99ms  cudaLaunchKernelExC

==3480030==       Range "ncclCommInitRank"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  362.61ms         1  362.61ms  362.61ms  362.61ms  ncclCommInitRank
 GPU activities:   60.61%  65.694us        97     677ns     607ns  2.5920us  [CUDA memset]
                   39.39%  42.686us        65     656ns     608ns  1.2480us  [CUDA memcpy HtoD]
      API calls:   52.20%  249.25us        65  3.8340us  2.3300us  31.774us  cudaMemcpyAsync
                   47.80%  228.22us        97  2.3520us  1.5700us  26.435us  cudaMemsetAsync

==3480030==     Domain "<unnamed>"
==3480030==       Range "InitOpt"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  22.813us         1  22.813us  22.813us  22.813us  InitOpt
 GPU activities:  100.00%  4.2847ms         2  2.1423ms  2.1372ms  2.1474ms  [CUDA memset]
      API calls:  100.00%  21.435us         2  10.717us  5.9370us  15.498us  cudaMemset

==3480030==       Range "Layer 0"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  7.6992ms        28  274.97us  154.88us  3.1140ms  Layer 0
 GPU activities:   67.23%  553.48ms       124  4.4635ms  1.4169ms  7.8166ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   17.92%  147.50ms        44  3.3523ms  1.7251ms  6.8719ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.05%  82.737ms        24  3.4474ms  1.5456ms  5.6854ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.47%  12.138ms        24  505.73us  503.35us  511.86us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.68%  5.6192ms        24  234.13us  213.85us  252.73us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.68%  5.6007ms        28  200.03us  199.13us  202.53us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.63%  5.2266ms        48  108.89us  104.99us  115.04us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.48%  3.9325ms         4  983.13us  977.10us  989.17us  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.3143ms        24  96.427us  81.567us  108.64us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.14%  1.1750ms         4  293.74us  291.83us  295.26us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.14%  1.1681ms         8  146.01us  143.33us  148.99us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.10%  807.60us         8  100.95us  86.399us  119.58us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.09%  760.37us         4  190.09us  187.39us  192.96us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  477.56us         4  119.39us  117.98us  120.29us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.03%  286.27us         8  35.783us  34.399us  36.735us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  29.089us         8  3.6360us  3.5530us  3.6800us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  8.9960us         8  1.1240us     545ns  1.2170us  [CUDA memset]
      API calls:   99.21%  2.2398ms       388  5.7720us  3.3020us  20.089us  cudaLaunchKernel
                    0.79%  17.750us         8  2.2180us  1.9980us  2.8600us  cudaMemsetAsync

==3480030==       Range "Layer 1"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.9129ms        28  104.03us  84.147us  189.09us  Layer 1
 GPU activities:   66.49%  532.66ms       124  4.2956ms  1.5219ms  7.8160ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.19%  145.71ms        44  3.3115ms  1.7418ms  6.8783ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.39%  83.252ms        24  3.4688ms  1.5862ms  5.6658ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.51%  12.118ms        24  504.90us  502.26us  511.13us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.70%  5.6030ms        28  200.11us  199.23us  202.30us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.69%  5.5290ms        24  230.38us  221.05us  253.05us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.66%  5.2599ms        48  109.58us  106.62us  112.89us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.49%  3.9462ms         4  986.54us  976.43us  991.66us  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.2377ms        24  93.238us  87.582us  108.73us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  1.1780ms         4  294.50us  292.83us  295.48us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.15%  1.1665ms         8  145.82us  143.17us  149.15us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.10%  825.49us         8  103.19us  86.271us  120.32us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.10%  771.09us         4  192.77us  190.72us  193.69us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  478.93us         4  119.73us  119.49us  119.97us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.04%  285.50us         8  35.687us  34.304us  36.863us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  28.894us         8  3.6110us  3.5520us  3.6800us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  8.3850us         8  1.0480us     544ns  1.2490us  [CUDA memset]
      API calls:   98.94%  1.7210ms       388  4.4350us  3.4290us  16.310us  cudaLaunchKernel
                    1.06%  18.366us         8  2.2950us  2.0330us  3.0690us  cudaMemsetAsync

==3480030==       Range "Layer 10"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.9964ms        28  107.02us  81.227us  213.45us  Layer 10
 GPU activities:   66.25%  520.61ms       124  4.1985ms  1.5393ms  6.6312ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.26%  143.50ms        44  3.2614ms  1.7159ms  6.8725ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.49%  82.403ms        24  3.4335ms  1.5452ms  5.6798ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.55%  12.172ms        24  507.17us  504.09us  511.38us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.71%  5.6056ms        28  200.20us  199.32us  202.59us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.69%  5.4147ms        24  225.61us  221.08us  231.13us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.67%  5.2749ms        48  109.89us  104.64us  115.42us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.50%  3.9108ms         4  977.69us  965.68us  989.36us  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.1867ms        24  91.112us  87.646us  95.166us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  1.1756ms         4  293.89us  293.12us  294.52us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.15%  1.1590ms         8  144.87us  142.40us  146.91us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.11%  825.78us         8  103.22us  86.591us  119.87us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.10%  759.51us         4  189.88us  187.16us  192.57us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  473.69us         4  118.42us  117.44us  120.09us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.04%  285.34us         8  35.667us  34.239us  37.055us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  29.279us         8  3.6590us  3.5510us  3.7440us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  8.2230us         8  1.0270us     512ns  1.2160us  [CUDA memset]
      API calls:   98.65%  1.7482ms       388  4.5050us  3.3980us  21.314us  cudaLaunchKernel
                    1.35%  23.912us         8  2.9890us  2.1150us  6.0490us  cudaMemsetAsync

==3480030==       Range "Layer 11"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  3.4879ms        28  124.57us  81.856us  571.54us  Layer 11
 GPU activities:   65.63%  520.65ms       124  4.1988ms  1.5391ms  6.5528ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.58%  147.37ms        44  3.3493ms  1.7744ms  7.2516ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.83%  85.946ms        24  3.5811ms  1.5911ms  5.9629ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.52%  12.085ms        24  503.55us  502.55us  504.79us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.71%  5.6059ms        28  200.21us  199.17us  202.27us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.68%  5.4114ms        24  225.48us  220.70us  230.68us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.67%  5.3116ms        48  110.66us  106.43us  115.26us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.51%  4.0105ms         4  1.0026ms  996.01us  1.0069ms  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.1833ms        24  90.969us  87.646us  95.038us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  1.1831ms         4  295.79us  293.85us  297.05us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.15%  1.1738ms         8  146.72us  144.29us  149.44us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.11%  834.93us         8  104.37us  86.366us  122.33us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.10%  779.32us         4  194.83us  193.02us  196.54us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  488.70us         4  122.17us  120.13us  123.42us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.04%  287.39us         8  35.923us  34.623us  37.536us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  30.303us         8  3.7870us  3.6800us  4.0000us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  9.1490us         8  1.1430us     512ns  1.2480us  [CUDA memset]
      API calls:   98.71%  1.8642ms       388  4.8040us  3.4400us  24.575us  cudaLaunchKernel
                    1.29%  24.418us         8  3.0520us  2.2800us  3.8190us  cudaMemsetAsync

==3480030==       Range "Layer 2"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.9074ms        28  103.84us  81.807us  196.42us  Layer 2
 GPU activities:   66.17%  522.22ms       124  4.2114ms  1.5440ms  7.7680ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.27%  144.23ms        44  3.2780ms  1.7411ms  6.8718ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.57%  83.441ms        24  3.4767ms  1.5864ms  5.7256ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.53%  12.106ms        24  504.41us  501.88us  513.21us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.71%  5.6074ms        28  200.27us  199.33us  202.72us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.69%  5.4297ms        24  226.24us  222.68us  252.60us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.67%  5.3255ms        48  110.95us  105.47us  115.93us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.50%  3.9540ms         4  988.51us  985.23us  993.49us  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.1915ms        24  91.311us  89.151us  108.67us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  1.1804ms         4  295.10us  293.98us  296.15us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.15%  1.1767ms         8  147.09us  145.85us  150.24us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.10%  817.42us         8  102.18us  86.590us  120.19us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.10%  775.00us         4  193.75us  193.47us  194.17us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  479.48us         4  119.87us  119.55us  120.16us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.04%  286.36us         8  35.795us  34.559us  36.991us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  29.152us         8  3.6440us  3.5200us  3.8080us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  9.6960us         8  1.2120us  1.1840us  1.2160us  [CUDA memset]
      API calls:   98.91%  1.7332ms       388  4.4660us  3.3050us  17.872us  cudaLaunchKernel
                    1.09%  19.032us         8  2.3790us  1.9560us  3.4180us  cudaMemsetAsync

==3480030==       Range "Layer 3"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  4.1736ms        28  149.06us  81.731us  1.2355ms  Layer 3
 GPU activities:   66.37%  520.32ms       124  4.1961ms  1.5386ms  7.8087ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.16%  142.37ms        44  3.2356ms  1.6644ms  6.8172ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.47%  82.076ms        24  3.4198ms  1.5236ms  5.7333ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.54%  12.103ms        24  504.31us  502.39us  513.72us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.71%  5.6046ms        28  200.17us  199.39us  202.49us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.69%  5.4242ms        24  226.01us  221.31us  253.79us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.67%  5.2708ms        48  109.81us  104.41us  115.20us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.50%  3.9259ms         4  981.47us  964.27us  994.57us  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.1848ms        24  91.033us  87.870us  108.61us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  1.1679ms         4  291.98us  291.45us  292.86us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.15%  1.1549ms         8  144.36us  141.53us  146.72us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.10%  822.45us         8  102.81us  86.078us  119.61us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.10%  766.77us         4  191.69us  188.32us  193.89us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  471.83us         4  117.96us  115.33us  119.90us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.04%  285.15us         8  35.643us  34.336us  36.831us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  28.384us         8  3.5480us  3.4560us  3.6160us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  8.9920us         8  1.1240us     576ns  1.2480us  [CUDA memset]
      API calls:   98.80%  2.8266ms       388  7.2850us  3.2980us  887.20us  cudaLaunchKernel
                    1.20%  34.307us         8  4.2880us  1.9660us  11.395us  cudaMemsetAsync

==3480030==       Range "Layer 4"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.9329ms        28  104.75us  81.468us  209.71us  Layer 4
 GPU activities:   66.43%  521.74ms       124  4.2075ms  1.5398ms  7.5830ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.18%  142.76ms        44  3.2446ms  1.6978ms  6.8460ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.40%  81.638ms        24  3.4016ms  1.5228ms  5.6877ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.55%  12.143ms        24  505.97us  504.47us  510.20us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.71%  5.6000ms        28  200.00us  199.20us  202.49us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.69%  5.4236ms        24  225.99us  222.11us  252.83us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.67%  5.2704ms        48  109.80us  107.14us  113.02us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.49%  3.8819ms         4  970.49us  964.24us  977.04us  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.1922ms        24  91.340us  87.679us  108.13us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  1.1849ms         4  296.22us  295.48us  296.86us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.15%  1.1620ms         8  145.25us  143.20us  148.73us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.10%  814.83us         8  101.85us  86.046us  119.77us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.10%  754.36us         4  188.59us  187.97us  190.27us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  468.95us         4  117.24us  115.13us  119.87us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.04%  284.86us         8  35.607us  34.335us  36.864us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  28.607us         8  3.5750us  3.4880us  3.6800us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  9.0550us         8  1.1310us     544ns  1.3450us  [CUDA memset]
      API calls:   98.91%  1.7486ms       388  4.5060us  3.2980us  22.137us  cudaLaunchKernel
                    1.09%  19.238us         8  2.4040us  1.9720us  3.5040us  cudaMemsetAsync

==3480030==       Range "Layer 5"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  3.8633ms        28  137.97us  81.607us  1.0800ms  Layer 5
 GPU activities:   66.19%  518.38ms       124  4.1805ms  1.4910ms  6.4686ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.28%  143.15ms        44  3.2535ms  1.7190ms  6.9069ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.53%  82.484ms        24  3.4369ms  1.5507ms  5.6557ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.54%  12.089ms        24  503.73us  501.72us  505.72us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.72%  5.6028ms        28  200.10us  199.26us  202.65us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.69%  5.4048ms        24  225.20us  220.92us  228.03us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.67%  5.2683ms        48  109.76us  107.29us  112.48us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.50%  3.9212ms         4  980.29us  966.06us  989.26us  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.1752ms        24  90.634us  85.982us  92.927us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  1.1707ms         4  292.67us  291.45us  293.79us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.15%  1.1541ms         8  144.27us  141.89us  146.21us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.10%  816.34us         8  102.04us  86.047us  120.03us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.10%  765.27us         4  191.32us  188.80us  193.79us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  475.70us         4  118.93us  117.66us  120.29us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.04%  286.62us         8  35.827us  34.591us  36.863us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  28.927us         8  3.6150us  3.5190us  3.7440us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  8.2880us         8  1.0360us     512ns  1.2160us  [CUDA memset]
      API calls:   99.39%  2.6828ms       388  6.9140us  3.3490us  972.50us  cudaLaunchKernel
                    0.61%  16.420us         8  2.0520us  1.9230us  2.1570us  cudaMemsetAsync

==3480030==       Range "Layer 6"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  3.1920ms        28  114.00us  82.067us  364.12us  Layer 6
 GPU activities:   66.06%  519.16ms       124  4.1867ms  1.5022ms  6.4594ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.33%  144.04ms        44  3.2736ms  1.7451ms  6.9528ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.61%  83.352ms        24  3.4730ms  1.5869ms  5.7379ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.54%  12.133ms        24  505.55us  503.13us  509.18us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.71%  5.6049ms        28  200.17us  199.36us  202.78us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.69%  5.4008ms        24  225.03us  219.10us  227.87us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.68%  5.3108ms        48  110.64us  106.56us  115.87us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.50%  3.9616ms         4  990.39us  988.69us  992.49us  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.1797ms        24  90.820us  85.950us  92.926us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  1.1740ms         8  146.75us  144.77us  149.66us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.15%  1.1714ms         4  292.84us  290.72us  295.26us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.10%  825.04us         8  103.13us  86.302us  120.25us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.10%  773.27us         4  193.32us  192.86us  193.57us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  479.93us         4  119.98us  119.71us  120.22us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.04%  285.37us         8  35.671us  34.368us  36.992us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  29.119us         8  3.6390us  3.5840us  3.6800us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  9.0550us         8  1.1310us     512ns  1.2480us  [CUDA memset]
      API calls:   99.10%  1.9870ms       388  5.1210us  3.2690us  120.39us  cudaLaunchKernel
                    0.90%  18.137us         8  2.2670us  1.9440us  2.8310us  cudaMemsetAsync

==3480030==       Range "Layer 7"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  3.0096ms        28  107.49us  81.277us  207.75us  Layer 7
 GPU activities:   66.24%  521.69ms       124  4.2072ms  1.5397ms  6.9702ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.25%  143.74ms        44  3.2669ms  1.6950ms  6.9153ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.53%  82.915ms        24  3.4548ms  1.5271ms  5.8087ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.54%  12.152ms        24  506.33us  504.02us  509.65us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.71%  5.6026ms        28  200.09us  199.04us  202.62us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.69%  5.4158ms        24  225.66us  222.72us  233.44us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.67%  5.2466ms        48  109.30us  105.73us  115.49us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.50%  3.9385ms         4  984.63us  969.23us  1.0031ms  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.1823ms        24  90.930us  87.838us  96.606us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  1.1702ms         4  292.55us  291.55us  294.39us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.15%  1.1636ms         8  145.45us  143.49us  148.51us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.10%  823.95us         8  102.99us  86.526us  120.00us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.10%  771.31us         4  192.83us  189.28us  196.70us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  475.19us         4  118.80us  116.00us  122.46us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.04%  286.91us         8  35.863us  34.496us  36.991us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  28.736us         8  3.5920us  3.5520us  3.7440us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  9.6640us         8  1.2080us  1.1520us  1.2480us  [CUDA memset]
      API calls:   98.91%  1.7745ms       388  4.5730us  3.2940us  41.552us  cudaLaunchKernel
                    1.09%  19.559us         8  2.4440us  1.9430us  3.1170us  cudaMemsetAsync

==3480030==       Range "Layer 8"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  3.0166ms        28  107.74us  81.131us  257.31us  Layer 8
 GPU activities:   66.35%  521.69ms       124  4.2072ms  1.5601ms  6.7708ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.20%  143.05ms        44  3.2512ms  1.6736ms  6.8766ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.46%  82.221ms        24  3.4259ms  1.5399ms  5.6822ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.55%  12.167ms        24  506.96us  503.99us  511.41us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.71%  5.6074ms        28  200.27us  199.39us  203.07us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.69%  5.4230ms        24  225.96us  222.97us  235.07us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.66%  5.2261ms        48  108.88us  104.64us  112.89us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.50%  3.9419ms         4  985.47us  977.49us  994.29us  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.1915ms        24  91.313us  88.926us  97.758us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  1.1820ms         4  295.50us  294.55us  296.70us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.15%  1.1533ms         8  144.17us  142.62us  145.15us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.10%  808.08us         8  101.01us  86.302us  119.01us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.10%  764.50us         4  191.12us  190.94us  191.26us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  473.88us         4  118.47us  117.21us  119.77us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.04%  284.41us         8  35.551us  34.079us  36.832us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  28.830us         8  3.6030us  3.4560us  3.7440us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  8.2870us         8  1.0350us     512ns  1.2160us  [CUDA memset]
      API calls:   98.92%  1.7904ms       388  4.6140us  3.3480us  64.604us  cudaLaunchKernel
                    1.08%  19.532us         8  2.4410us  1.9300us  4.3830us  cudaMemsetAsync

==3480030==       Range "Layer 9"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.9270ms        28  104.54us  82.131us  199.90us  Layer 9
 GPU activities:   66.49%  522.16ms       124  4.2109ms  1.5398ms  6.6444ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.12%  142.32ms        44  3.2346ms  1.6932ms  6.7804ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.39%  81.572ms        24  3.3988ms  1.5277ms  5.5850ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.54%  12.107ms        24  504.47us  502.29us  508.18us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.71%  5.5995ms        28  199.98us  199.23us  202.27us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.69%  5.4243ms        24  226.01us  222.56us  233.88us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.68%  5.3306ms        48  111.05us  106.91us  115.84us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.50%  3.8894ms         4  972.36us  967.73us  977.61us  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.28%  2.1899ms        24  91.247us  87.263us  96.670us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  1.1761ms         4  294.02us  292.03us  296.73us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.15%  1.1540ms         8  144.25us  143.23us  145.41us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.10%  815.79us         8  101.97us  86.207us  119.97us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.10%  757.10us         4  189.28us  188.00us  190.65us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.06%  467.19us         4  116.80us  115.71us  117.25us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.04%  285.08us         8  35.635us  34.303us  36.831us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  28.478us         8  3.5590us  3.5190us  3.6800us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  8.8960us         8  1.1120us     512ns  1.2160us  [CUDA memset]
      API calls:   98.96%  1.7261ms       388  4.4480us  3.3700us  17.795us  cudaLaunchKernel
                    1.04%  18.177us         8  2.2720us  2.1540us  2.6140us  cudaMemsetAsync

==3480030==       Range "Train step 0"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  9.53508s         1  9.53508s  9.53508s  9.53508s  Train step 0
 GPU activities:   81.23%  7.72190s      1293  5.9721ms  1.4910ms  115.18ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.26%  975.36ms       313  3.1162ms  1.6978ms  139.17ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    3.62%  344.48ms        73  4.7189ms  1.5228ms  96.025ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.34%  127.33ms       252  505.27us  501.72us  513.72us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    1.00%  94.803ms        21  4.5144ms  4.4474ms  4.6235ms  void fused_classifier_kernel5<bool=1, bool=0>(__nv_bfloat16*, float*, __nv_bfloat16*, float, int const *, int, int, int, int, std::integral_constant<bool, bool=1>)
                    0.60%  57.178ms       252  226.90us  219.10us  253.79us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.58%  55.421ms       504  109.96us  104.41us  115.93us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.56%  52.766ms       264  199.87us  199.04us  202.62us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.24%  23.118ms       252  91.739us  85.950us  108.73us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.15%  14.096ms        16  880.99us  2.4320us  4.3714ms  void adamw_kernel3<__nv_bfloat16, __nv_bfloat16>(__nv_bfloat16*, float*, __nv_bfloat16*, float*, float*, unsigned long, long, long, long, float, float, float, float, float, float, float, float, unsigned int)
                    0.12%  11.819ms        12  984.92us  965.68us  1.0038ms  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.06%  5.4616ms        51  107.09us     512ns  2.1474ms  [CUDA memset]
                    0.04%  3.6328ms        25  145.31us  141.89us  150.24us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.04%  3.5274ms        12  293.95us  291.45us  296.86us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.04%  3.4662ms        16  216.64us  1.8880us  1.0675ms  void copy_and_cast_kernel<float, __nv_bfloat16>(float*, __nv_bfloat16 const *, unsigned long, long, long)
                    0.03%  2.5841ms         1  2.5841ms  2.5841ms  2.5841ms  void global_norm_squared_kernel<__nv_bfloat16>(float*, __nv_bfloat16 const *, unsigned long, long)
                    0.03%  2.4510ms        24  102.12us  86.175us  121.63us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.02%  2.2978ms        12  191.49us  187.16us  196.25us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.02%  1.4282ms        12  119.01us  115.13us  122.72us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.01%  1.3407ms        21  63.844us  61.599us  68.798us  encoder_forward_kernel3(__nv_bfloat16*, int const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int)
                    0.01%  1.0221ms        21  48.672us  46.783us  60.383us  layernorm_forward_kernel6(__nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.01%  855.38us        24  35.640us  34.079us  37.536us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.00%  138.98us        44  3.1580us  2.6550us  7.4560us  [CUDA memcpy HtoD]
                    0.00%  86.877us        24  3.6190us  3.5200us  3.7440us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.00%  65.151us         1  65.151us  65.151us  65.151us  void wte_backward_kernel<int=256>(__nv_bfloat16*, int4 const *, int const *, __nv_bfloat16 const *, int const *, unsigned int, int, int, int)
                    0.00%  62.431us        22  2.8370us  1.7920us  3.8710us  [CUDA memcpy DtoH]
                    0.00%  30.271us         1  30.271us  30.271us  30.271us  wpe_backward_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int const *, int, int, int, unsigned int)
                    0.00%  14.368us         1  14.368us  14.368us  14.368us  ncclKernel_SendRecv_RING_SIMPLE_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)
                    0.00%  7.9040us         2  3.9520us  3.2960us  4.6080us  void global_sum_single_block_kernel<float>(float*, float const *, unsigned long)
      API calls:   86.23%  814.99ms         1  814.99ms  814.99ms  814.99ms  cudaLaunchKernelExC
                   11.15%  105.41ms        63  1.6732ms  12.072us  10.266ms  cudaMemcpy
                    2.47%  23.379ms      3448  6.7800us  3.2980us  5.4846ms  cudaLaunchKernel
                    0.12%  1.1249ms        23  48.908us  5.9370us  68.980us  cudaMemset
                    0.01%  131.95us        28  4.7120us  2.0490us  51.222us  cudaMemsetAsync
                    0.01%  94.955us         3  31.651us  20.175us  39.325us  cudaMemcpyAsync

==3480030==       Range "Train step 1"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.23676s         1  1.23676s  1.23676s  1.23676s  Train step 1
 GPU activities:   34.86%  430.78ms        73  5.9011ms  1.6932ms  133.22ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   32.17%  397.53ms        73  5.4457ms  1.4169ms  112.11ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   27.66%  341.73ms        73  4.6813ms  1.5277ms  93.468ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.14%  14.061ms        16  878.83us  2.5920us  4.3483ms  void adamw_kernel3<__nv_bfloat16, __nv_bfloat16>(__nv_bfloat16*, float*, __nv_bfloat16*, float*, float*, unsigned long, long, long, long, float, float, float, float, float, float, float, float, unsigned int)
                    0.95%  11.795ms        12  982.94us  964.24us  1.0031ms  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.49%  6.0663ms        12  505.53us  502.33us  509.94us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.39%  4.8268ms        24  201.12us  199.36us  203.07us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.37%  4.5883ms         1  4.5883ms  4.5883ms  4.5883ms  void fused_classifier_kernel5<bool=1, bool=0>(__nv_bfloat16*, float*, __nv_bfloat16*, float, int const *, int, int, int, int, std::integral_constant<bool, bool=1>)
                    0.29%  3.6357ms        25  145.43us  142.40us  148.51us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.29%  3.5325ms        12  294.37us  290.72us  297.05us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.22%  2.7020ms        12  225.17us  213.85us  230.49us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.21%  2.6364ms        24  109.85us  104.99us  114.33us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.20%  2.4681ms        24  102.84us  86.046us  121.66us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.19%  2.2999ms        12  191.66us  187.97us  196.70us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.18%  2.1788ms         1  2.1788ms  2.1788ms  2.1788ms  void global_norm_squared_kernel<__nv_bfloat16>(float*, __nv_bfloat16 const *, unsigned long, long)
                    0.12%  1.4237ms        12  118.64us  115.71us  122.46us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.09%  1.1238ms        29  38.752us     512ns  1.0640ms  [CUDA memset]
                    0.09%  1.0898ms        12  90.814us  81.567us  94.910us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.07%  856.11us        24  35.671us  34.239us  36.992us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.01%  86.941us        24  3.6220us  3.4880us  3.8400us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.01%  66.046us         1  66.046us  66.046us  66.046us  void wte_backward_kernel<int=256>(__nv_bfloat16*, int4 const *, int const *, __nv_bfloat16 const *, int const *, unsigned int, int, int, int)
                    0.01%  65.184us         1  65.184us  65.184us  65.184us  encoder_forward_kernel3(__nv_bfloat16*, int const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int)
                    0.00%  45.536us         1  45.536us  45.536us  45.536us  layernorm_forward_kernel6(__nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.00%  30.143us         1  30.143us  30.143us  30.143us  wpe_backward_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int const *, int, int, int, unsigned int)
                    0.00%  19.872us         4  4.9680us  2.9440us  7.4560us  [CUDA memcpy HtoD]
                    0.00%  14.368us         1  14.368us  14.368us  14.368us  ncclKernel_SendRecv_RING_SIMPLE_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)
                    0.00%  7.7430us         2  3.8710us  3.2960us  4.4470us  void global_sum_single_block_kernel<float>(float*, float const *, unsigned long)
                    0.00%  3.5840us         2  1.7920us  1.4080us  2.1760us  [CUDA memcpy DtoH]
      API calls:   99.31%  807.23ms         3  269.08ms  14.899us  807.19ms  cudaMemcpyAsync
                    0.40%  3.2877ms         3  1.0959ms  23.728us  2.1850ms  cudaMemcpy
                    0.27%  2.1740ms       472  4.6050us  3.2980us  35.028us  cudaLaunchKernel
                    0.02%  135.90us        28  4.8530us  1.9230us  51.425us  cudaMemsetAsync
                    0.00%  9.3790us         1  9.3790us  9.3790us  9.3790us  cudaLaunchKernelExC
                    0.00%  8.4590us         1  8.4590us  8.4590us  8.4590us  cudaMemset

==3480030==       Range "Train step 2"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.24076s         1  1.24076s  1.24076s  1.24076s  Train step 2
 GPU activities:   34.81%  431.57ms        73  5.9120ms  1.6950ms  133.73ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   32.22%  399.45ms        73  5.4719ms  1.5219ms  112.16ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   27.67%  343.04ms        73  4.6991ms  1.5271ms  94.483ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.14%  14.072ms        16  879.51us  2.7200us  4.3558ms  void adamw_kernel3<__nv_bfloat16, __nv_bfloat16>(__nv_bfloat16*, float*, __nv_bfloat16*, float*, float*, unsigned long, long, long, long, float, float, float, float, float, float, float, float, unsigned int)
                    0.95%  11.796ms        12  983.03us  966.06us  1.0038ms  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.49%  6.0589ms        12  504.91us  502.61us  507.80us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.39%  4.8267ms        24  201.11us  199.23us  202.78us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.37%  4.5314ms         1  4.5314ms  4.5314ms  4.5314ms  void fused_classifier_kernel5<bool=1, bool=0>(__nv_bfloat16*, float*, __nv_bfloat16*, float, int const *, int, int, int, int, std::integral_constant<bool, bool=1>)
                    0.29%  3.6322ms        25  145.29us  143.04us  149.15us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.28%  3.5307ms        12  294.22us  292.41us  296.25us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.22%  2.7131ms        12  226.09us  221.05us  233.88us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.21%  2.6375ms        24  109.90us  105.60us  115.87us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.20%  2.4511ms        24  102.13us  86.078us  122.14us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.19%  2.2966ms        12  191.38us  188.80us  193.89us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.18%  2.1753ms         1  2.1753ms  2.1753ms  2.1753ms  void global_norm_squared_kernel<__nv_bfloat16>(float*, __nv_bfloat16 const *, unsigned long, long)
                    0.12%  1.4268ms        12  118.90us  116.00us  122.43us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.09%  1.1220ms        29  38.690us     512ns  1.0627ms  [CUDA memset]
                    0.09%  1.0965ms        12  91.376us  87.582us  96.670us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.07%  858.10us        24  35.754us  34.304us  36.992us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.01%  86.970us        24  3.6230us  3.4880us  3.7760us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.01%  68.190us         1  68.190us  68.190us  68.190us  void wte_backward_kernel<int=256>(__nv_bfloat16*, int4 const *, int const *, __nv_bfloat16 const *, int const *, unsigned int, int, int, int)
                    0.01%  66.878us         1  66.878us  66.878us  66.878us  encoder_forward_kernel3(__nv_bfloat16*, int const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int)
                    0.00%  45.472us         1  45.472us  45.472us  45.472us  layernorm_forward_kernel6(__nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.00%  30.048us         1  30.048us  30.048us  30.048us  wpe_backward_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int const *, int, int, int, unsigned int)
                    0.00%  19.808us         4  4.9520us  2.5920us  7.3280us  [CUDA memcpy HtoD]
                    0.00%  14.720us         1  14.720us  14.720us  14.720us  ncclKernel_SendRecv_RING_SIMPLE_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)
                    0.00%  8.0000us         2  4.0000us  3.2320us  4.7680us  void global_sum_single_block_kernel<float>(float*, float const *, unsigned long)
                    0.00%  2.8480us         2  1.4240us  1.4080us  1.4400us  [CUDA memcpy DtoH]
      API calls:   99.17%  807.39ms         3  269.13ms  14.300us  807.35ms  cudaMemcpyAsync
                    0.40%  3.2885ms         3  1.0962ms  25.505us  2.1780ms  cudaMemcpy
                    0.40%  3.2706ms       472  6.9290us  3.2690us  887.20us  cudaLaunchKernel
                    0.02%  161.54us        28  5.7690us  1.9460us  48.618us  cudaMemsetAsync
                    0.00%  16.159us         1  16.159us  16.159us  16.159us  cudaLaunchKernelExC
                    0.00%  8.9940us         1  8.9940us  8.9940us  8.9940us  cudaMemset

==3480030==       Range "attention_backward"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  2.8062ms        48  58.463us  47.356us  248.05us  attention_backward
 GPU activities:   37.86%  181.02ms        96  1.8856ms  1.8215ms  1.9575ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   26.18%  125.14ms        48  2.6071ms  2.5195ms  2.7116ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   22.96%  109.79ms        48  2.2872ms  2.2107ms  2.3747ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    9.88%  47.214ms        48  983.63us  964.24us  1.0069ms  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    1.92%  9.1978ms        48  191.62us  187.16us  196.70us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    1.19%  5.7110ms        48  118.98us  115.13us  123.42us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
      API calls:  100.00%  1.6699ms       336  4.9690us  3.3400us  72.047us  cudaLaunchKernel

==3480030==       Range "attention_forward"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  10.348ms       288  35.929us  29.853us  182.22us  attention_forward
 GPU activities:   45.40%  733.87ms       288  2.5482ms  2.2186ms  3.0927ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   39.92%  645.35ms       288  2.2408ms  1.9685ms  2.7358ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    9.00%  145.51ms       288  505.26us  501.72us  513.72us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    4.04%  65.321ms       288  226.81us  213.85us  253.79us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    1.63%  26.409ms       288  91.698us  81.567us  108.73us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
      API calls:  100.00%  6.6879ms      1440  4.6440us  3.3480us  120.39us  cudaLaunchKernel

==3480030==       Range "classifier_and_loss"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  3.35310s        24  139.71ms  4.5893ms  821.25ms  classifier_and_loss
 GPU activities:   48.59%  1.62437s       244  6.6572ms  1.6644ms  139.17ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   40.98%  1.37017s       292  4.6924ms  1.5228ms  96.025ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    3.74%  125.14ms        48  2.6071ms  2.5195ms  2.7116ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    3.25%  108.52ms        24  4.5218ms  4.4474ms  4.6235ms  void fused_classifier_kernel5<bool=1, bool=0>(__nv_bfloat16*, float*, __nv_bfloat16*, float, int const *, int, int, int, int, std::integral_constant<bool, bool=1>)
                    1.41%  47.214ms        48  983.63us  964.24us  1.0069ms  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.44%  14.549ms       100  145.49us  141.53us  150.24us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.42%  14.115ms        48  294.07us  290.72us  297.05us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.29%  9.8377ms        96  102.48us  86.046us  122.33us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.29%  9.7130ms        48  202.35us  201.85us  203.07us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.28%  9.1978ms        48  191.62us  187.16us  196.70us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.17%  5.7110ms        48  118.98us  115.13us  123.42us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.10%  3.4292ms        96  35.721us  34.079us  37.536us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.01%  347.80us        96  3.6220us  3.4560us  4.0000us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.01%  273.28us       124  2.2030us     512ns  30.207us  [CUDA memset]
                    0.01%  264.03us         4  66.006us  64.639us  68.190us  void wte_backward_kernel<int=256>(__nv_bfloat16*, int4 const *, int const *, __nv_bfloat16 const *, int const *, unsigned int, int, int, int)
                    0.00%  127.01us        32  3.9690us  2.6560us  7.7440us  [CUDA memcpy HtoD]
                    0.00%  120.86us         4  30.215us  30.048us  30.399us  wpe_backward_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int const *, int, int, int, unsigned int)
                    0.00%  65.695us        24  2.7370us  1.4400us  3.8710us  [CUDA memcpy DtoH]
                    0.00%  57.632us         4  14.408us  14.176us  14.720us  ncclKernel_SendRecv_RING_SIMPLE_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)
                    0.00%  18.303us         4  4.5750us  4.4470us  4.7680us  void global_sum_single_block_kernel<float>(float*, float const *, unsigned long)
      API calls:   72.48%  2.42131s        12  201.78ms  13.774us  807.35ms  cudaMemcpyAsync
                   24.40%  815.02ms         4  203.76ms  9.3790us  814.99ms  cudaLaunchKernelExC
                    2.86%  95.479ms        44  2.1700ms  25.523us  4.6372ms  cudaMemcpy
                    0.22%  7.3368ms      1248  5.8780us  3.2690us  887.20us  cudaLaunchKernel
                    0.03%  1.1306ms        24  47.107us  8.4590us  68.980us  cudaMemset
                    0.01%  265.00us       100  2.6500us  1.9230us  11.395us  cudaMemsetAsync

==3480030==       Range "encoder_backward"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  7.0929ms         4  1.7732ms  1.4508ms  1.9720ms  encoder_backward
 GPU activities:   59.81%  264.03us         4  66.006us  64.639us  68.190us  void wte_backward_kernel<int=256>(__nv_bfloat16*, int4 const *, int const *, __nv_bfloat16 const *, int const *, unsigned int, int, int, int)
                   27.38%  120.86us         4  30.215us  30.048us  30.399us  wpe_backward_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int const *, int, int, int, unsigned int)
                   12.82%  56.576us         8  7.0720us  6.5280us  7.7440us  [CUDA memcpy HtoD]
      API calls:   70.10%  187.09us         8  23.386us  13.774us  35.455us  cudaMemcpyAsync
                   29.90%  79.811us         8  9.9760us  5.0640us  16.904us  cudaLaunchKernel

==3480030==       Range "encoder_forward"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  5.8945ms        24  245.60us  10.718us  5.4922ms  encoder_forward
 GPU activities:  100.00%  1.5387ms        24  64.113us  61.599us  68.798us  encoder_forward_kernel3(__nv_bfloat16*, int const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int)
      API calls:  100.00%  5.8388ms        24  243.29us  9.0600us  5.4846ms  cudaLaunchKernel

==3480030==       Range "fused_classifier"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  625.24us        24  26.051us  20.921us  33.273us  fused_classifier
 GPU activities:  100.00%  108.52ms        24  4.5218ms  4.4474ms  4.6235ms  void fused_classifier_kernel5<bool=1, bool=0>(__nv_bfloat16*, float*, __nv_bfloat16*, float, int const *, int, int, int, int, std::integral_constant<bool, bool=1>)
      API calls:  100.00%  503.19us        24  20.966us  17.156us  28.255us  cudaLaunchKernel

==3480030==       Range "gelu_backward_inplace"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  237.24us        48  4.9420us  4.1060us  8.2930us  gelu_backward_inplace
 GPU activities:  100.00%  14.115ms        48  294.07us  290.72us  297.05us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
      API calls:  100.00%  200.25us        48  4.1710us  3.4150us  7.1540us  cudaLaunchKernel

==3480030==       Range "gelu_forward"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.7421ms       336  5.1840us  4.0320us  21.867us  gelu_forward
 GPU activities:  100.00%  67.245ms       336  200.13us  199.04us  203.07us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
      API calls:  100.00%  1.4772ms       336  4.3960us  3.3490us  21.110us  cudaLaunchKernel

==3480030==       Range "gpt2_backward_and_reduce"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  3.26001s         4  815.00ms  812.27ms  821.32ms  gpt2_backward_and_reduce
 GPU activities:   49.87%  1.62437s       244  6.6572ms  1.6644ms  139.17ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   42.07%  1.37017s       292  4.6924ms  1.5228ms  96.025ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    3.84%  125.14ms        48  2.6071ms  2.5195ms  2.7116ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.45%  47.214ms        48  983.63us  964.24us  1.0069ms  softmax_autoregressive_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, float)
                    0.56%  18.216ms         4  4.5539ms  4.4947ms  4.6011ms  void fused_classifier_kernel5<bool=1, bool=0>(__nv_bfloat16*, float*, __nv_bfloat16*, float, int const *, int, int, int, int, std::integral_constant<bool, bool=1>)
                    0.45%  14.549ms       100  145.49us  141.53us  150.24us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.43%  14.115ms        48  294.07us  290.72us  297.05us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.30%  9.8377ms        96  102.48us  86.046us  122.33us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.30%  9.7130ms        48  202.35us  201.85us  203.07us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.28%  9.1978ms        48  191.62us  187.16us  196.70us  permute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int, int)
                    0.18%  5.7110ms        48  118.98us  115.13us  123.42us  unpermute_kernel_backward(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.14%  4.4991ms       112  40.170us     512ns  1.0710ms  [CUDA memset]
                    0.11%  3.4292ms        96  35.721us  34.079us  37.536us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.01%  347.80us        96  3.6220us  3.4560us  4.0000us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
                    0.01%  264.03us         4  66.006us  64.639us  68.190us  void wte_backward_kernel<int=256>(__nv_bfloat16*, int4 const *, int const *, __nv_bfloat16 const *, int const *, unsigned int, int, int, int)
                    0.00%  120.86us         4  30.215us  30.048us  30.399us  wpe_backward_kernel(__nv_bfloat16*, __nv_bfloat16 const *, int const *, int, int, int, unsigned int)
                    0.00%  68.544us        12  5.7120us  2.7200us  7.7440us  [CUDA memcpy HtoD]
                    0.00%  57.632us         4  14.408us  14.176us  14.720us  ncclKernel_SendRecv_RING_SIMPLE_Sum_int8_t(ncclDevComm*, unsigned long, ncclWork*)
                    0.00%  18.303us         4  4.5750us  4.4470us  4.7680us  void global_sum_single_block_kernel<float>(float*, float const *, unsigned long)
                    0.00%  7.8080us         4  1.9520us  1.4400us  2.7520us  [CUDA memcpy DtoH]
      API calls:   74.55%  2.42131s        12  201.78ms  13.774us  807.35ms  cudaMemcpyAsync
                   25.09%  815.02ms         4  203.76ms  9.3790us  814.99ms  cudaLaunchKernelExC
                    0.21%  6.9083ms      1228  5.6250us  3.2690us  887.20us  cudaLaunchKernel
                    0.13%  4.3293ms         4  1.0823ms  1.0784ms  1.0869ms  cudaMemcpy
                    0.02%  497.80us       108  4.6090us  1.9230us  53.753us  cudaMemsetAsync
                    0.00%  37.047us         4  9.2610us  8.4590us  9.9380us  cudaMemset

==3480030==       Range "gpt2_calculate_grad_norm"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  9.4525ms         4  2.3631ms  2.2600ms  2.6433ms  gpt2_calculate_grad_norm
 GPU activities:   99.77%  9.1262ms         4  2.2816ms  2.1753ms  2.5841ms  void global_norm_squared_kernel<__nv_bfloat16>(float*, __nv_bfloat16 const *, unsigned long, long)
                    0.14%  13.120us         4  3.2800us  3.2320us  3.2960us  void global_sum_single_block_kernel<float>(float*, float const *, unsigned long)
                    0.07%  6.0170us         4  1.5040us  1.4080us  1.7920us  [CUDA memcpy DtoH]
                    0.03%  2.3030us         4     575ns     544ns     608ns  [CUDA memset]
      API calls:   97.17%  9.1555ms         4  2.2889ms  2.1780ms  2.5956ms  cudaMemcpy
                    1.82%  171.84us         8  21.479us  6.9340us  45.185us  cudaLaunchKernel
                    1.01%  95.080us         4  23.770us  11.156us  35.891us  cudaMemsetAsync

==3480030==       Range "gpt2_forward"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  9.82600s        24  409.42ms  396.87ms  439.85ms  gpt2_forward
 GPU activities:   89.73%  8.79586s      1464  6.0081ms  1.4169ms  115.18ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    6.58%  645.35ms       288  2.2408ms  1.9685ms  2.7358ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.48%  145.51ms       288  505.26us  501.72us  513.72us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    0.67%  65.321ms       288  226.81us  213.85us  253.79us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.65%  63.322ms       576  109.93us  104.41us  115.93us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.59%  57.532ms       288  199.76us  199.04us  200.57us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.27%  26.409ms       288  91.698us  81.567us  108.73us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.02%  1.5387ms        24  64.113us  61.599us  68.798us  encoder_forward_kernel3(__nv_bfloat16*, int const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int)
                    0.01%  1.1599ms        24  48.328us  45.472us  60.383us  layernorm_forward_kernel6(__nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.00%  72.030us        24  3.0010us  2.5920us  3.6480us  [CUDA memcpy HtoD]
      API calls:   68.74%  23.463ms      3528  6.6500us  3.3480us  5.4846ms  cudaLaunchKernel
                   31.26%  10.671ms        24  444.62us  12.072us  10.266ms  cudaMemcpy

==3480030==       Range "gpt2_update"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  64.197ms         4  16.049ms  14.080ms  21.902ms  gpt2_update
 GPU activities:   87.89%  56.273ms        64  879.27us  2.4320us  4.3714ms  void adamw_kernel3<__nv_bfloat16, __nv_bfloat16>(__nv_bfloat16*, float*, __nv_bfloat16*, float*, float*, unsigned long, long, long, long, float, float, float, float, float, float, float, float, unsigned int)
                    6.69%  4.2847ms         2  2.1423ms  2.1372ms  2.1474ms  [CUDA memset]
                    5.41%  3.4662ms        16  216.64us  1.8880us  1.0675ms  void copy_and_cast_kernel<float, __nv_bfloat16>(float*, __nv_bfloat16 const *, unsigned long, long, long)
      API calls:   94.70%  382.87us        80  4.7850us  3.3870us  27.960us  cudaLaunchKernel
                    5.30%  21.435us         2  10.717us  5.9370us  15.498us  cudaMemset

==3480030==       Range "layernorm_backward"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  811.63us       100  8.1160us  6.1320us  19.136us  layernorm_backward
 GPU activities:   99.24%  14.549ms       100  145.49us  141.53us  150.24us  layernorm_backward_kernel10(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, float const *, float const *, int, int, int)
                    0.76%  110.75us       100  1.1070us     512ns  1.6960us  [CUDA memset]
      API calls:   63.04%  452.05us       100  4.5200us  3.2940us  15.712us  cudaLaunchKernel
                   36.96%  265.00us       100  2.6500us  1.9230us  11.395us  cudaMemsetAsync

==3480030==       Range "layernorm_forward"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  393.17us        24  16.382us  12.458us  57.309us  layernorm_forward
 GPU activities:  100.00%  1.1599ms        24  48.328us  45.472us  60.383us  layernorm_forward_kernel6(__nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
      API calls:  100.00%  254.70us        24  10.612us  7.7240us  48.950us  cudaLaunchKernel

==3480030==       Range "matmul_backward"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  7.3049ms       196  37.270us  21.094us  1.0411ms  matmul_backward
 GPU activities:   55.45%  1.51458s       196  7.7274ms  1.6644ms  139.17ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   43.54%  1.18915s       196  6.0671ms  1.5228ms  96.025ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    0.52%  14.115ms        48  294.07us  290.72us  297.05us  gelu_backward_inplace_kernel(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.36%  9.8377ms        96  102.48us  86.046us  122.33us  void matmul_backward_bias_kernel9<__nv_bfloat16, bool=1>(__nv_bfloat16*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.13%  3.4292ms        96  35.721us  34.079us  37.536us  void matmul_backward_bias_kernel9<float, bool=1>(float*, __nv_bfloat16 const *, int, int, int, std::integral_constant<bool, bool=1>)
                    0.01%  347.80us        96  3.6220us  3.4560us  4.0000us  reduce_add_sum_kernel(__nv_bfloat16*, float const *, unsigned long, unsigned long)
      API calls:  100.00%  4.3760ms       728  6.0100us  3.2690us  887.20us  cudaLaunchKernel

==3480030==       Range "matmul_cublaslt"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  27.393ms      2336  11.726us  7.5150us  2.8024ms  matmul_cublaslt
 GPU activities:   71.02%  8.92100s      1512  5.9001ms  1.4169ms  115.18ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   18.07%  2.26972s       532  4.2664ms  1.6644ms  139.17ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                   10.91%  1.37017s       292  4.6924ms  1.5228ms  96.025ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=1, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
      API calls:  100.00%  11.547ms      2336  4.9430us  3.5740us  120.39us  cudaLaunchKernel

==3480030==       Range "validation"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  8.28010s         1  8.28010s  8.28010s  8.28010s  validation
 GPU activities:   88.74%  7.32383s      1220  6.0031ms  1.4910ms  115.18ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=1, bool=0, int=6, int=4, int=6, int=3, int=4>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    6.52%  538.25ms       240  2.2427ms  2.0647ms  2.7358ms  void magma_sgemmEx_kernel<float, __nv_bfloat16, __nv_bfloat16, bool=0, bool=0, int=6, int=3, int=5, int=3, int=3>(int, int, int, Tensor, int, Tensor, int, Tensor, int, Tensor, int, int, int, float const *, float const *, float, float, int, cublasLtEpilogue_t, int, void const *, long)
                    1.47%  121.27ms       240  505.30us  501.72us  513.72us  softmax_forward_kernel5(__nv_bfloat16*, float, __nv_bfloat16 const *, int, int)
                    1.09%  90.309ms        20  4.5154ms  4.4474ms  4.6235ms  void fused_classifier_kernel5<bool=1, bool=0>(__nv_bfloat16*, float*, __nv_bfloat16*, float, int const *, int, int, int, int, std::integral_constant<bool, bool=1>)
                    0.66%  54.456ms       240  226.90us  219.10us  253.79us  permute_kernel(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16 const *, int, int, int, int)
                    0.64%  52.789ms       480  109.98us  104.41us  115.93us  fused_residual_forward_kernel5(__nv_bfloat16*, __nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.58%  47.944ms       240  199.76us  199.04us  200.57us  gelu_forward_kernel2(__nv_bfloat16*, __nv_bfloat16 const *)
                    0.27%  22.015ms       240  91.730us  85.950us  108.73us  unpermute_kernel(__nv_bfloat16*, __nv_bfloat16*, int, int, int, int)
                    0.02%  1.2775ms        20  63.877us  61.599us  68.798us  encoder_forward_kernel3(__nv_bfloat16*, int const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int, int)
                    0.01%  974.13us        20  48.706us  46.783us  60.383us  layernorm_forward_kernel6(__nv_bfloat16*, float*, float*, __nv_bfloat16 const *, __nv_bfloat16 const *, __nv_bfloat16 const *, int, int)
                    0.00%  118.98us        40  2.9740us  2.6550us  3.6480us  [CUDA memcpy HtoD]
                    0.00%  57.887us        20  2.8940us  2.6560us  3.8710us  [CUDA memcpy DtoH]
                    0.00%  45.440us        20  2.2720us  1.9840us  2.4640us  [CUDA memset]
      API calls:   82.11%  101.71ms        60  1.6952ms  12.072us  10.266ms  cudaMemcpy
                   17.01%  21.066ms      2960  7.1160us  3.3480us  5.4846ms  cudaLaunchKernel
                    0.88%  1.0935ms        20  54.676us  48.337us  68.980us  cudaMemset

